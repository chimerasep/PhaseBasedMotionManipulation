<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Phase-Based Motion Manipulation for VR Cybersickness Reduction</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>
<body>
    <nav class="navbar">
        <div class="container">
            <h1>Phase Based Motion Manipulation</h1>
            <ul class="nav-links">
                <li><a href="#overview">Overview</a></li>
                <li><a href="#methodology">Methodology</a></li>
                <li><a href="#implementation">Implementation</a></li>
                <li><a href="#comparison">Comparison</a></li>
                <li><a href="#results">Results</a></li>
                <li><a href="#team">Team</a></li>
                <li><a href="#downloads">Downloads</a></li>
            </ul>
        </div>
    </nav>

    <header class="hero">
        <div class="container">
            <h1>Phase-Based Motion Manipulation</h1>
            <p>Advanced VR Cybersickness Reduction Through Real-Time Phase Processing</p>
            <div class="hero-description">
                <p>Welcome to our innovative graduation project that addresses one of the most significant challenges in virtual reality: cybersickness. By leveraging advanced phase-based motion processing techniques, we have developed a real-time solution that reduces motion perception in VR environments, creating a more comfortable and immersive experience for users.</p>
            </div>
        </div>
    </header>

    <section id="overview" class="section">
        <div class="container">
            <h2>Project Overview</h2>
            <div class="overview-content">
                <p>Virtual reality cybersickness affects millions of users worldwide, limiting the adoption and enjoyment of VR technologies. Our solution uses phase-based image processing to generate counter-motion images that trick the brain into perceiving reduced motion, significantly decreasing cybersickness symptoms.</p>
                
                <div class="achievements">
                    <h3>Key Achievements</h3>
                    <div class="achievement-grid">
                        <div class="achievement">
                            <i class="fas fa-clock"></i>
                            <h4>Real-time Performance</h4>
                            <p>Implemented shader-based processing in Unity for zero-latency application</p>
                        </div>
                        <div class="achievement">
                            <i class="fas fa-wave-square"></i>
                            <h4>Advanced Signal Processing</h4>
                            <p>Utilized FFT-based phase analysis in YIQ color space</p>
                        </div>
                        <div class="achievement">
                            <i class="fas fa-vr-cardboard"></i>
                            <h4>Practical Application</h4>
                            <p>Created a working VR system that demonstrably reduces cybersickness</p>
                        </div>
                    </div>
                </div>

                <div class="challenge-solution">
                    <div class="challenge">
                        <h3>The Challenge</h3>
                        <p>Cybersickness in virtual reality environments is a persistent problem that affects user comfort and limits VR adoption. Traditional approaches often involve hardware modifications or basic software adjustments that don't address the fundamental perceptual issues causing motion sickness.</p>
                    </div>
                    <div class="solution">
                        <h3>Our Solution</h3>
                        <p>Inspired by the groundbreaking work in phase-based motion magnification by Wadhwa et al., we developed an innovative approach that processes visual information in real-time to reduce perceived motion. Instead of magnifying subtle motions as in the original research, we apply inverse processing to create counter-motions that reduce the brain's perception of movement.</p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section id="methodology" class="section">
        <div class="container">
            <h2>Methodology & Technical Approach</h2>
            <div class="methodology-content">
                <h3>Theoretical Foundation</h3>
                <p>Our approach is grounded in the principle that phase variations in complex-valued image representations correspond directly to motion. By analyzing and manipulating these phase variations, we can influence motion perception without traditional optical flow computation.</p>
                
                <div class="processing-pipeline">
                    <h3>Processing Pipeline</h3>
                    <div class="pipeline-stages">
                        <div class="stage">
                            <div class="stage-number">1</div>
                            <h4>Image Acquisition</h4>
                            <ul>
                                <li>Capture current and previous frames from Unity VR environment</li>
                                <li>Convert RGB color space to YIQ for optimized luminance processing</li>
                                <li>Isolate luma channel for phase analysis</li>
                            </ul>
                        </div>
                        <div class="stage">
                            <div class="stage-number">2</div>
                            <h4>Frequency Domain Analysis</h4>
                            <ul>
                                <li>Apply Fast Fourier Transform (FFT) to luma channels</li>
                                <li>Extract phase information from complex frequency representations</li>
                                <li>Calculate phase delta: Δφ = φ_previous - φ_current</li>
                            </ul>
                        </div>
                        <div class="stage">
                            <div class="stage-number">3</div>
                            <h4>Phase Manipulation</h4>
                            <ul>
                                <li>Apply bandpass filtering to eliminate irrelevant frequency components</li>
                                <li>Implement controlled magnification/reduction to target phases</li>
                                <li>Maintain spatial coherence while reducing motion perception</li>
                            </ul>
                        </div>
                        <div class="stage">
                            <div class="stage-number">4</div>
                            <h4>Reconstruction</h4>
                            <ul>
                                <li>Reconstruct processed frames using inverse FFT</li>
                                <li>Convert back to RGB color space</li>
                                <li>Output to VR display system in real-time</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section id="implementation" class="section">
        <div class="container">
            <h2>Implementation Details</h2>
            <div class="implementation-content">
                <div class="development-phases">
                    <h3>Development Phases</h3>
                    <div class="phase">
                        <h4>Phase 1: Proof of Concept</h4>
                        <p><strong>Objective:</strong> Validate the theoretical approach using modified existing algorithms</p>
                        <div class="phase-details">
                            <div class="approach">
                                <h5>Approach:</h5>
                                <ul>
                                    <li>Modified code from established phase-based motion magnification implementations</li>
                                    <li>Processed Unity-captured frames through external processing pipeline</li>
                                    <li>Implemented basic frame-to-frame phase analysis</li>
                                </ul>
                            </div>
                            <div class="challenges">
                                <h5>Challenges:</h5>
                                <ul>
                                    <li>Significant processing latency (>10000ms)</li>
                                    <li>Memory bottlenecks in data transfer</li>
                                    <li>Insufficient frame rate for real-time VR applications</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    <div class="phase">
                        <h4>Phase 2: Real-Time Implementation (GPU-based)</h4>
                        <p><strong>Objective:</strong> Achieve real-time performance suitable for VR applications</p>
                        <div class="technical-specs">
                            <h5>Technical Specifications:</h5>
                            <ul>
                                <li>Platform: Unity 3D with custom HLSL shaders</li>
                                <li>Processing Target: 30+ FPS for smooth VR experience</li>
                                <li>Latency Requirement: <20ms total processing time</li>
                                <li>Resolution Support: Up to 2160x1200 per eye</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section id="comparison" class="section">
        <div class="container">
            <h2>Before & After Comparison</h2>
            <div class="comparison-slider">
                <div class="comparison-container">
                    <img src="assets/after.gif" alt="Before" class="comparison-img comparison-img-before">
                    <img src="assets/before.gif" alt="After" class="comparison-img comparison-img-after">
                    <div class="comparison-handle"></div>
                </div>
                <p class="comparison-caption">Drag the handle to compare the before and after processing results.</p>
            </div>

            <!-- Video Comparison 1: main.mp4 vs 05.mp4 -->
            <div class="video-comparison-section">
                <h3>Comparison 1: Unprocessed vs without pyramid (0.5 lower bound)</h3>
                <p class="comparison-description">.</p>
                <div class="video-comparison-slider">
                    <div class="video-comparison-container">
                        <video src="assets/main.mp4" class="comparison-video comparison-video-before" loop muted></video>
                        <video src="assets/05.mp4" class="comparison-video comparison-video-after" loop muted></video>
                        <div class="video-comparison-handle"></div>
                    </div>
                    <p class="comparison-caption">Drag the handle to compare</p>
                </div>
            </div>

            <!-- Video Comparison 2: main.mp4 vs 06.mp4 -->
            <div class="video-comparison-section">
                <h3>Comparison 2: Unprocessed vs without pyramid (0.6 lower bound)</h3>
                <p class="comparison-description">.</p>
                <div class="video-comparison-slider">
                    <div class="video-comparison-container">
                        <video src="assets/main.mp4" class="comparison-video comparison-video-before" loop muted></video>
                        <video src="assets/06.mp4" class="comparison-video comparison-video-after" loop muted></video>
                        <div class="video-comparison-handle"></div>
                    </div>
                    <p class="comparison-caption">Drag the handle to compare</p>
                </div>
            </div>

            <!-- Video Comparison 3: main.mp4 vs 191.mp4 -->
            <div class="video-comparison-section">
                <h3>Comparison 3: Unprocessed vs Pyramidlevel 3  191</h3>
                <p class="comparison-description">.</p>
                <div class="video-comparison-slider">
                    <div class="video-comparison-container">
                        <video src="assets/main.mp4" class="comparison-video comparison-video-before" loop muted></video>
                        <video src="assets/191.mp4" class="comparison-video comparison-video-after" loop muted></video>
                        <div class="video-comparison-handle"></div>
                    </div>
                    <p class="comparison-caption">Drag the handle to compare</p>
                </div>
            </div>


            <div class="video-comparison-section">
                <h3>Comparison 4: Unprocessed vs Pyramidlevel 3 170</h3>
                <p class="comparison-description">.</p>
                <div class="video-comparison-slider">
                    <div class="video-comparison-container">
                        <video src="assets/main.mp4" class="comparison-video comparison-video-before" loop muted></video>
                        <video src="assets/191.mp4" class="comparison-video comparison-video-after" loop muted></video>
                        <div class="video-comparison-handle"></div>
                    </div>
                    <p class="comparison-caption">Drag the handle to compare</p>
                </div>
            </div>

            <div class="video-comparison-section">
                <h3>Comparison 5:  Unprocessed vs Pyramidlevel 2 170</h3>
                <p class="comparison-description">.</p>
                <div class="video-comparison-slider">
                    <div class="video-comparison-container">
                        <video src="assets/main.mp4" class="comparison-video comparison-video-before" loop muted></video>
                        <video src="assets/pyramidlevel2-170.mp4" class="comparison-video comparison-video-after" loop muted></video>
                        <div class="video-comparison-handle"></div>
                    </div>
                    <p class="comparison-caption">Drag the handle to compare</p>
                </div>
            </div>
        </div>
    </section>

    <section id="results" class="section">
        <div class="container">
            <h2>Results & Discussion</h2>
            <div class="results-content">
                <div class="table-section">
                    <div class="table-container">
                        <p>To objectively measure the efficacy of our motion suppression algorithms, we conducted a comprehensive dense optical flow analysis. This technique computes motion vectors for each pixel between consecutive frames, allowing us to quantify the total magnitude of visual motion presented to the user. We compared our two primary approaches—a direct FFT method with bandpass filtering (Non-Pyramid) and a Steerable Pyramid method—against the unprocessed baseline footage.
                            The results, summarized in Table 1, demonstrate a profound reduction in motion across all tested configurations.
                            </p>
                        <img src="assets/table.png" alt="Table 1: Comparative Optical Flow Analysis of Motion Suppression Techniques" class="results-table">
                        <p class="table-caption">Table 1: Comparative Optical Flow Analysis of Motion Suppression Techniques</p>
                    </div>
                </div>
                
                <div class="discussion-section">
                    <h3>Discussion</h3>
                    <p>The primary finding is that all tested methods were highly effective, achieving a motion magnitude reduction between 70% and 73%. This is a substantial decrease in optical flow, providing strong quantitative evidence that the core phase-manipulation technique successfully suppresses the visual motion signals responsible for the sensory conflict that causes cybersickness.
                        <br>
                        Numerically, the 4-level Steerable Pyramid approach (0.191-0.45 Freq) achieved the highest raw motion reduction at 73.3%. However, as will be discussed next, this marginal numerical superiority came at a significant cost to visual quality and performance stability. The non-pyramid methods provided a robust and stable reduction of ~71%, positioning them as highly viable candidates.
                    </p>
                </div>
            </div>
        </div>
    </section>

    <section id="team" class="section">
        <div class="container">
            <h2>Our Team</h2>
            <div class="team-content">
                <p class="team-intro"></p>
                
                <div class="team-grid">
                    <!-- Supervisor Section -->
                    <div class="supervisor-section">
                        <div class="team-member">
                            <img src="assets/ufukcelikcan.jpg" alt="Ufuk Çelikcan">
                            <h3>Doç. Dr. Ufuk Çelikcan</h3>
                            <p>Supervisor</p>
                        </div>
                    </div>
                    
                    <!-- Students Section -->
                    <div class="students-section">
                        <div class="team-member">
                            <img src="assets/placeholder.jpg" alt="Kenan Gökdeniz Acet">
                            <h3>Kenan Gökdeniz Acet</h3>
                            <p>Student ID: 2200356034</p>
                        </div>
                        <div class="team-member">
                            <img src="assets/placeholder.jpg" alt="Emre Can Şahin">
                            <h3>Emre Can Şahin</h3>
                            <p>Student ID: 2210356146</p>
                        </div>
                    </div>
                </div>

                <div class="research-inspiration">
                    <h3>Research Inspiration</h3>
                    <p>Our work builds upon the groundbreaking research in phase-based motion magnification by Wadhwa et al. from MIT. Their innovative approach to revealing imperceptible motions through phase manipulation inspired us to explore the inverse application: reducing perceived motion to minimize cybersickness.</p>
                </div>
            </div>
        </div>
    </section>

    <section id="downloads" class="section">
        <div class="container">
            <h2>Downloads & Resources</h2>
            <div class="downloads-content">
                <div class="download-categories">
                    <div class="category">
                        <h3>Project Deliverables</h3>
                        <a href="https://github.com/KenanGokdenizAcet/phase-based-motion-manipulation" class="download-link">
                            <div class="download-item">
                                <i class="fas fa-download"></i>
                                <div class="item-info">
                                    <h4>Unity Demo</h4>
                                    <p>Complete executable demo with installation guide</p>
                                </div>
                            </div>
                        
                        <a href="https://github.com/chimerasep/PhaseBasedMotionManipulation/tree/main/sc" class="download-link" target="_blank">
                            <div class="download-item">
                                <i class="fas fa-code"></i>
                                <div class="item-info">
                                    <h4>Source Code</h4>
                                    <p>Script and shader implementations only</p>
                                </div>
                            </div>
                        </a>
                    </div>
                    <div class="category">
                        <h3>Presentations</h3>
                        <a href="assets/presentations/project_presentation.zip" class="download-link">
                            <div class="download-item">
                                <i class="fas fa-presentation"></i>
                                <div class="item-info">
                                    <h4>Presentation Materials</h4>
                                    <p>Project poster and presentation slides</p>
                                </div>
                            </div>
                        </a>
                        <a href="assets/videos/demo_video.mp4" class="download-link">
                            <div class="download-item">
                                <i class="fas fa-video"></i>
                                <div class="item-info">
                                    <h4>Video Demonstration</h4>
                                    <p>2-minute technical demonstration of the system</p>
                                </div>
                            </div>
                        </a>
                        
                    </div>
                </div>
            </div>
        </div>
    </section>

    <footer>
        <div class="container">
            <p>&copy; 2024 Phase-Based Motion Manipulation Project.</p>
            <p>-</p>
            <div class="social-links">
                <a href="#"><i class="fab fa-github"></i></a>
                
            </div>
        </div>
    </footer>

    <script>
    // Navbar scroll behavior
    document.addEventListener('DOMContentLoaded', function() {
        const navbar = document.querySelector('.navbar');
        let lastScrollTop = 0;
        let scrollThreshold = 20;
        
        window.addEventListener('scroll', function() {
            let scrollTop = window.pageYOffset || document.documentElement.scrollTop;
            
            if (scrollTop > lastScrollTop + scrollThreshold) { 
                navbar.classList.add('hidden');
                lastScrollTop = scrollTop;
            } else if (scrollTop < lastScrollTop - scrollThreshold) {
                navbar.classList.remove('hidden');
                lastScrollTop = scrollTop;
            }
            
            if (scrollTop < 10) {
                navbar.classList.remove('hidden');
            }
        });
    });

    // Image comparison slider
    window.addEventListener('DOMContentLoaded', function() {
        const container = document.querySelector('.comparison-container');
        const beforeImg = document.querySelector('.comparison-img-before');
        const handle = document.querySelector('.comparison-handle');
        
        if (container && beforeImg && handle) {
            let dragging = false;
            const setPosition = (x) => {
                const rect = container.getBoundingClientRect();
                let pos = Math.max(0, Math.min(x - rect.left, rect.width));
                beforeImg.style.clipPath = `inset(0 ${rect.width - pos}px 0 0)`;
                handle.style.left = `${pos}px`;
                handle.style.transform = 'translateX(-50%)';
            };
            
            handle.addEventListener('mousedown', (e) => { dragging = true; });
            window.addEventListener('mouseup', () => { dragging = false; });
            window.addEventListener('mousemove', (e) => {
                if (dragging) setPosition(e.clientX);
            });
            handle.addEventListener('touchstart', (e) => { dragging = true; });
            window.addEventListener('touchend', () => { dragging = false; });
            window.addEventListener('touchmove', (e) => {
                if (dragging && e.touches[0]) setPosition(e.touches[0].clientX);
            });
            // Initial position - start at center
            setTimeout(() => {
                setPosition(container.offsetWidth / 2);
            }, 100);
            
            // Resize handler
            window.addEventListener('resize', () => {
                setTimeout(() => {
                    setPosition(container.offsetWidth / 2);
                }, 100);
            });
        }
    });

    // Video comparison sliders
    window.addEventListener('DOMContentLoaded', function() {
        const videoContainers = document.querySelectorAll('.video-comparison-container');
        
        videoContainers.forEach((container, index) => {
            const beforeVideo = container.querySelector('.comparison-video-before');
            const afterVideo = container.querySelector('.comparison-video-after');
            const handle = container.querySelector('.video-comparison-handle');
            
            if (!beforeVideo || !afterVideo || !handle) return;
            
            // Auto-play videos when they come into view
            const observer = new IntersectionObserver((entries) => {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        beforeVideo.play();
                        afterVideo.play();
                    } else {
                        beforeVideo.pause();
                        afterVideo.pause();
                    }
                });
            }, { threshold: 0.5 });
            
            observer.observe(container);
            
            let dragging = false;
            const setVideoPosition = (x) => {
                const rect = container.getBoundingClientRect();
                let pos = Math.max(0, Math.min(x - rect.left, rect.width));
                beforeVideo.style.clipPath = `inset(0 ${rect.width - pos}px 0 0)`;
                handle.style.left = `${pos}px`;
                handle.style.transform = 'translateX(-50%)';
            };
            
            handle.addEventListener('mousedown', (e) => { 
                dragging = true;
                beforeVideo.play();
                afterVideo.play();
            });
            
            window.addEventListener('mouseup', () => { dragging = false; });
            
            window.addEventListener('mousemove', (e) => {
                if (dragging) setVideoPosition(e.clientX);
            });
            
            // Touch support
            handle.addEventListener('touchstart', (e) => { 
                dragging = true;
                beforeVideo.play();
                afterVideo.play();
            });
            
            window.addEventListener('touchend', () => { dragging = false; });
            
            window.addEventListener('touchmove', (e) => {
                if (dragging && e.touches[0]) setVideoPosition(e.touches[0].clientX);
            });
            
            // Initial position for video
            setTimeout(() => {
                setVideoPosition(container.offsetWidth / 2);
            }, 100);
            
            // Resize handler for video
            window.addEventListener('resize', () => {
                setTimeout(() => {
                    setVideoPosition(container.offsetWidth / 2);
                }, 100);
            });
        });
    });
    </script>
</body>
</html> 